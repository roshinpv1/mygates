# CodeGates LLM Configuration
# Choose one or more LLM providers

# OpenAI Configuration (Cloud)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_MODEL=gpt-4
# OPENAI_TEMPERATURE=0.1
# OPENAI_MAX_TOKENS=4000

# Anthropic Configuration (Cloud)
# ANTHROPIC_API_KEY=your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_TEMPERATURE=0.1
# ANTHROPIC_MAX_TOKENS=4000

# Local LLM Configuration (Free, Private)
LOCAL_LLM_URL=http://localhost:11434/v1
LOCAL_LLM_MODEL=meta-llama-3.1-8b-instruct
LOCAL_LLM_API_KEY=not-needed
LOCAL_LLM_TEMPERATURE=0.1
LOCAL_LLM_MAX_TOKENS=4000

# Alternative Local LLM URLs (uncomment to use)
# LOCAL_LLM_URL=http://localhost:1234/v1
# LOCAL_LLM_URL=http://localhost:8080/v1

# Ollama Configuration (Alternative Local)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=meta-llama-3.1-8b-instruct
OLLAMA_TEMPERATURE=0.1
OLLAMA_NUM_PREDICT=4000

# Enterprise LLM Configuration (if applicable)
# ENTERPRISE_LLM_URL=https://your-enterprise-llm-endpoint
# ENTERPRISE_LLM_MODEL=meta-llama-3.1-8b-instruct
# ENTERPRISE_LLM_API_KEY=your-enterprise-api-key
# ENTERPRISE_LLM_TOKEN=your-enterprise-token
# ENTERPRISE_LLM_REFRESH_URL=https://your-token-refresh-endpoint
# ENTERPRISE_LLM_CLIENT_ID=your-client-id
# ENTERPRISE_LLM_CLIENT_SECRET=your-client-secret
# ENTERPRISE_LLM_HEADERS={}
# ENTERPRISE_LLM_TEMPERATURE=0.1
# ENTERPRISE_LLM_MAX_TOKENS=4000

# CodeGates Configuration
CODEGATES_LOG_LEVEL=INFO
CODEGATES_MAX_FILE_SIZE=1048576
CODEGATES_EXCLUDE_PATTERNS=node_modules/**,.git/**,**/__pycache__/**
